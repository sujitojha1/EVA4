{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4_S15_Solution_DenseDepth_step3",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitojha1/EVA4/blob/rev8/S15/EVA4_S15_Solution_DenseDepth_step3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMbuTXj0GPCR",
        "colab_type": "text"
      },
      "source": [
        "# EVA4 Session 15 Assignment - DepthMap & Mask Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-ZppzRz6GTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvjmNa1FJJ1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "05c5e6f8-3a03-4aef-bca3-f150bf88edf7"
      },
      "source": [
        "!pip install kornia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/60/f0c174c4a2a40b10b04b37c43f5afee3701cc145b48441a2dc5cf9286c3c/kornia-0.3.1-py2.py3-none-any.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 32.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 1.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.4)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->kornia) (0.16.0)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwp4CN5IMTyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch\n",
        "from kornia.losses import SSIM\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJrJa7CoG_9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root = Path('./data/')\n",
        "\n",
        "f1,f2,f3 = data_root/'bg', data_root/'fg_bg', data_root/'mask'\n",
        "\n",
        "print(len(list(f1.iterdir())))\n",
        "print(len(list(f2.iterdir())))\n",
        "print(len(list(f3.iterdir())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb29rZtRPBho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale_transform = transforms.Compose([\n",
        "                                      transforms.Resize((256,256)),\n",
        "                                      transforms.ToTensor()\n",
        "                                      ])\n",
        "\n",
        "class MasterDataset(Dataset):\n",
        "  def __init__(self, data_root, transform=None):\n",
        "    self.f1_files = list(f1.glob('*.jpg'))\n",
        "    self.f2_files = list(f2.glob('*.jpg'))\n",
        "    self.f3_files = list(f3.glob('*.jpg'))\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.f1_files)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    f1_image = Image.open(self.f1_files[index])\n",
        "    f2_image = Image.open(self.f2_files[index])\n",
        "    f3_image = Image.open(self.f3_files[index])\n",
        "\n",
        "    f1_image = scale_transform(f1_image)\n",
        "    f2_image = scale_transform(f2_image)\n",
        "    f3_image = scale_transform(f3_image)\n",
        "\n",
        "    return {'f1': f1_image, 'f2': f2_image, 'f3': f3_image}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PneULwQ8TRQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean, std = torch.tensor([0.485,0.456,0.406])*255, torch.tensor([0.229,0.224,0.225])*255\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.Resize((256,256)),\n",
        "                                       transforms.ColorJitter(brightness=0.05, contrast= 0.05, saturation = 0.05, hue = 0.05),\n",
        "                                       transforms.ToTensor()\n",
        "                                       ])\n",
        "\n",
        "train_ds = MasterDataset(data_root, train_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsGMVjA-Uw0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(k,v.shape) for k,v in train_ds[0].items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33rZRUwnU_lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuoeROBnVJOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtMIBysXVOhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(k,v.shape) for k,v in sample.items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3gdiB2RVjb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = sample['f1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAS6YKj3VoGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_tensor = torchvision.utils.make_grid(imgs, 2)\n",
        "grid_image = grid_tensor.permute(1,2,0)\n",
        "\n",
        "def show(tensors, figsize = (10,10), *args, **kwargs):\n",
        "  try:\n",
        "    tensors = tensors.detach().cpu()\n",
        "  except:\n",
        "    pass\n",
        "  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)\n",
        "  grid_image = grid_tensor.permute(1,2,0)\n",
        "\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.imshow(grid_image)\n",
        "\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def show_pred(tensors, *args, **kwargs):\n",
        "  tensors = (tensors * std[None,:,None,None]) + mean[None,:,None,None]\n",
        "  show(tensors, *args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhRAF7v1Yfqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show(imgs, nrow=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3b264gYj29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvGen(nn.Module):\n",
        "  '''Generator'''\n",
        "  def __init__(self):\n",
        "    super(ConvGen,self).__init__()\n",
        "\n",
        "    self.convblock1 = nn.Sequential(\n",
        "        nn.Conv2d(3,32,3,stride=1,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.convblock2 = nn.Sequential(\n",
        "        nn.Conv2d(32,32,3,stride=1,padding=1,bias=False,group=32),\n",
        "        nn.Conv2d(32,64,1,stride=1,padding=0,bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.convblock3 = nn.Sequential(\n",
        "        nn.Conv2d(128,256,3,stride=1,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.convblock4 = nn.Sequential(\n",
        "        nn.Conv2d(256,3,3,stride=1,padding=1,bias=False),\n",
        "    )\n",
        "\n",
        "  def forward(self,sample):\n",
        "    f1=sample['f1']\n",
        "    f2=sample['f2']\n",
        "\n",
        "    f1 = self.convblock2(self.convblock1(f1))\n",
        "    f2 = self.convblock2(self.convblock1(f2))\n",
        "\n",
        "    f = torch.cat([f1,f2],dim=1)\n",
        "    f = self.convblock4(self.convblock3(f))\n",
        "\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiKO0HoeceiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk6slZpscoz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvGen()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq_TnQaUczZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}